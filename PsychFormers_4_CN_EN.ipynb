{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b18a8d4ad67d477f861706eb10c5c6e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_57964339f15d497499d98de589300427",
              "IPY_MODEL_d0fac44e2f324e48bceb9d40cf2a5d3c",
              "IPY_MODEL_25fde9721c7a4414aa61017eac03e817"
            ],
            "layout": "IPY_MODEL_ebb7f2351d034ce5940096a877ccd059"
          }
        },
        "57964339f15d497499d98de589300427": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9e7d3ea9df4e1b95687940a3e76022",
            "placeholder": "​",
            "style": "IPY_MODEL_44bee4f6e38f44eabcd89fb326f76348",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d0fac44e2f324e48bceb9d40cf2a5d3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02055fd4c9404aba8a4ad063ef071245",
            "max": 236,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_98a8a218d41c4d4998f4e0656956d59a",
            "value": 236
          }
        },
        "25fde9721c7a4414aa61017eac03e817": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e04053aa4c1404db7e0f40a04b49fc5",
            "placeholder": "​",
            "style": "IPY_MODEL_ee1b3a5b05ed4d739ce205ed599c3196",
            "value": " 236/236 [00:00&lt;00:00, 24.6kB/s]"
          }
        },
        "ebb7f2351d034ce5940096a877ccd059": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b9e7d3ea9df4e1b95687940a3e76022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44bee4f6e38f44eabcd89fb326f76348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02055fd4c9404aba8a4ad063ef071245": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98a8a218d41c4d4998f4e0656956d59a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e04053aa4c1404db7e0f40a04b49fc5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee1b3a5b05ed4d739ce205ed599c3196": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "16a0923fdfc14c2e8d41e8808bbfe393": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4e3fff7b3555462288c5ad4a89f81170",
              "IPY_MODEL_4a7358c75d284b94b42b1da886aa1bba",
              "IPY_MODEL_347a77047ba6457787696d7929254744"
            ],
            "layout": "IPY_MODEL_51e22764e2744a1bb72e5a21504be7f5"
          }
        },
        "4e3fff7b3555462288c5ad4a89f81170": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_191562d7f7f240b4930d68a423081ba2",
            "placeholder": "​",
            "style": "IPY_MODEL_d42d73def45645fe871e60913be98286",
            "value": "vocab.json: 100%"
          }
        },
        "4a7358c75d284b94b42b1da886aa1bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61673cdf2b364666adddaec0a06f86ef",
            "max": 798156,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2da524d068144a7b8f89fa5d47f40fed",
            "value": 798156
          }
        },
        "347a77047ba6457787696d7929254744": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04742611830c47f49fc4ffe1909f75a5",
            "placeholder": "​",
            "style": "IPY_MODEL_bd5dd151cf8240089c55bc3549d4a81e",
            "value": " 798k/798k [00:00&lt;00:00, 11.2MB/s]"
          }
        },
        "51e22764e2744a1bb72e5a21504be7f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "191562d7f7f240b4930d68a423081ba2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d42d73def45645fe871e60913be98286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61673cdf2b364666adddaec0a06f86ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2da524d068144a7b8f89fa5d47f40fed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04742611830c47f49fc4ffe1909f75a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd5dd151cf8240089c55bc3549d4a81e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c24c8df340c64a6797c73c2d65b2316d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1e3e25b13274488194fa41b72806e5f0",
              "IPY_MODEL_ab246629e4e84c9195a08f28af06c6c8",
              "IPY_MODEL_9e4de2ac2f884d55897bd3128d3128d6"
            ],
            "layout": "IPY_MODEL_b5c582b1df8e4101a32f0a23be6cb92f"
          }
        },
        "1e3e25b13274488194fa41b72806e5f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_72ed1e83f4d7482ba49191df9ddc55aa",
            "placeholder": "​",
            "style": "IPY_MODEL_ffa84c19c5b442a8a24c27bc1aeed308",
            "value": "merges.txt: 100%"
          }
        },
        "ab246629e4e84c9195a08f28af06c6c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48587f809e804064abe0e4293935a627",
            "max": 456356,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bcf20adfaeb94fb387084f423aaf0fb6",
            "value": 456356
          }
        },
        "9e4de2ac2f884d55897bd3128d3128d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bbf2c71678e2430091ef260bd63ee1a5",
            "placeholder": "​",
            "style": "IPY_MODEL_30a4cd7f36cb4bf0a0e2a0113253fc86",
            "value": " 456k/456k [00:00&lt;00:00, 26.7MB/s]"
          }
        },
        "b5c582b1df8e4101a32f0a23be6cb92f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72ed1e83f4d7482ba49191df9ddc55aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffa84c19c5b442a8a24c27bc1aeed308": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48587f809e804064abe0e4293935a627": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcf20adfaeb94fb387084f423aaf0fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bbf2c71678e2430091ef260bd63ee1a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30a4cd7f36cb4bf0a0e2a0113253fc86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "67c4eab084f644ad9b553c34543d2d94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b3cd1301de74e13a82ed87338cb8cfc",
              "IPY_MODEL_102edf0b4c554ad98108e1a812042c04",
              "IPY_MODEL_d29db0d625ef48d0a896979789384759"
            ],
            "layout": "IPY_MODEL_cb82bc3b977f431da72095521e427140"
          }
        },
        "2b3cd1301de74e13a82ed87338cb8cfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5cf1dbc08294eb9ae8690b24039e0c4",
            "placeholder": "​",
            "style": "IPY_MODEL_ee0ba1585d574e92bf04a0b21ff43e24",
            "value": "tokenizer.json: 100%"
          }
        },
        "102edf0b4c554ad98108e1a812042c04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24a5942d7c1c49768a1b97e51bd2a536",
            "max": 1355270,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f08fc6b6e0a143f49e3d0e2efd675340",
            "value": 1355270
          }
        },
        "d29db0d625ef48d0a896979789384759": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c062779fa434f3db3bc929288dc61a0",
            "placeholder": "​",
            "style": "IPY_MODEL_556555f975e44d13974a3b83334d325e",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 27.7MB/s]"
          }
        },
        "cb82bc3b977f431da72095521e427140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5cf1dbc08294eb9ae8690b24039e0c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee0ba1585d574e92bf04a0b21ff43e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24a5942d7c1c49768a1b97e51bd2a536": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f08fc6b6e0a143f49e3d0e2efd675340": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c062779fa434f3db3bc929288dc61a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556555f975e44d13974a3b83334d325e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfb7c75848d7484cad77d157d6bf67dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d54ce618e50449185a98c5478d841b7",
              "IPY_MODEL_c35c188cff534345b9b1360c6a55aaa4",
              "IPY_MODEL_1fcd30b3e4e5463181bf9ae607fee3d6"
            ],
            "layout": "IPY_MODEL_bec41b5e03844e6d9655407a26cf2070"
          }
        },
        "5d54ce618e50449185a98c5478d841b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_206cecacc480446a9c9b76039b817825",
            "placeholder": "​",
            "style": "IPY_MODEL_b7279984c95c40cc9e58a247387cd6ad",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "c35c188cff534345b9b1360c6a55aaa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a5218404fe04443c9f2d36d86ff4f40a",
            "max": 90,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18ccbcd84d9741268c88688690c6ec94",
            "value": 90
          }
        },
        "1fcd30b3e4e5463181bf9ae607fee3d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a4b39ead96a46eea3e9ea428c317a90",
            "placeholder": "​",
            "style": "IPY_MODEL_89c4f2e1085f4e008f7ee3bcd51624da",
            "value": " 90.0/90.0 [00:00&lt;00:00, 8.06kB/s]"
          }
        },
        "bec41b5e03844e6d9655407a26cf2070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "206cecacc480446a9c9b76039b817825": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7279984c95c40cc9e58a247387cd6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5218404fe04443c9f2d36d86ff4f40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18ccbcd84d9741268c88688690c6ec94": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a4b39ead96a46eea3e9ea428c317a90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "89c4f2e1085f4e008f7ee3bcd51624da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d70b64f136942859b0213312ada09e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3b819d8fd284c398062505eb733f4bf",
              "IPY_MODEL_fc2e502d24ee4197af338d09fa93b52c",
              "IPY_MODEL_e18cab76591a466bab5f7166001c1eb9"
            ],
            "layout": "IPY_MODEL_053e6a8a3d244640898e95cd92d5c20e"
          }
        },
        "b3b819d8fd284c398062505eb733f4bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30eb3d6a10024546bfd188625694b40a",
            "placeholder": "​",
            "style": "IPY_MODEL_2e5bdf9341d24f1ea1cd334a1ab4423e",
            "value": "config.json: 100%"
          }
        },
        "fc2e502d24ee4197af338d09fa93b52c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b7b2a6ec8441579acbc18dcefc7850",
            "max": 739,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_36dd5faa1abd48249ffbb900aa41a1bf",
            "value": 739
          }
        },
        "e18cab76591a466bab5f7166001c1eb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd7f6a30f7814c688f4e74e002ac3bd3",
            "placeholder": "​",
            "style": "IPY_MODEL_29cf035ddc1d40848c2975e33f89102f",
            "value": " 739/739 [00:00&lt;00:00, 68.3kB/s]"
          }
        },
        "053e6a8a3d244640898e95cd92d5c20e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30eb3d6a10024546bfd188625694b40a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e5bdf9341d24f1ea1cd334a1ab4423e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34b7b2a6ec8441579acbc18dcefc7850": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36dd5faa1abd48249ffbb900aa41a1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd7f6a30f7814c688f4e74e002ac3bd3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29cf035ddc1d40848c2975e33f89102f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59522c73be824fb381422d51e9969517": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_610a44aa952049e0b3df9d5c623a03f9",
              "IPY_MODEL_1f4180b09d2f4760a8fa0e59846c6a34",
              "IPY_MODEL_96e1a2e31b69451abbee48bb20df0064"
            ],
            "layout": "IPY_MODEL_ddb96b6ea87b403e930f5cd6c3562201"
          }
        },
        "610a44aa952049e0b3df9d5c623a03f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f697623267364d5f893b6cd59eb1fbd2",
            "placeholder": "​",
            "style": "IPY_MODEL_f0ef719afcf842f48d2efa41ed904850",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "1f4180b09d2f4760a8fa0e59846c6a34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_923854fa798c4a7eb7ecd05e6c15d9c3",
            "max": 7175586541,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_213d2790225749eaa9037f7d238033d4",
            "value": 7175586541
          }
        },
        "96e1a2e31b69451abbee48bb20df0064": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e6264e55a5a421096be5219d0104f60",
            "placeholder": "​",
            "style": "IPY_MODEL_b43d981838e043e4887b7a814dad1afe",
            "value": " 7.18G/7.18G [00:34&lt;00:00, 171MB/s]"
          }
        },
        "ddb96b6ea87b403e930f5cd6c3562201": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f697623267364d5f893b6cd59eb1fbd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f0ef719afcf842f48d2efa41ed904850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "923854fa798c4a7eb7ecd05e6c15d9c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "213d2790225749eaa9037f7d238033d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6e6264e55a5a421096be5219d0104f60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b43d981838e043e4887b7a814dad1afe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This is a Transformer Tool used to calculate the word-level surprisal. Code is based on\n",
        "@article{michaelov_2022_AnaphoricZeroPronouns,\n",
        "  title={Do language models make human-like predictions about the coreferents of Italian anaphoric zero pronouns?},\n",
        "  author={Michaelov, James A. and Bergen, Benjamin K.},\n",
        "  journal={arXiv preprint arXiv:2208.14554},\n",
        "  year={2022}\n",
        "}"
      ],
      "metadata": {
        "id": "sBgoVPiIS_Gg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "psychformers general from github\n"
      ],
      "metadata": {
        "id": "0iVKNqhP_SsA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "from transformers import AutoTokenizer,AutoModelForCausalLM,AutoModelForMaskedLM\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='Calculates surprisal and other metrics...')\n",
        "\n",
        "    parser.add_argument('--stimuli', '-i', type=str, default=\"/content/drive/MyDrive/PsychFormers/Stimuli.txt\",\n",
        "                        help='stimuli to test')\n",
        "    parser.add_argument('--stimuli_list', '-ii', type=str, default=None,\n",
        "                        help='path to file containing list of stimulus files to test')\n",
        "    parser.add_argument('--output_directory', '-o', type=str, default='/content/drive/MyDrive/PsychFormers/output',\n",
        "                        help='output directory')\n",
        "    parser.add_argument('--primary_decoder', '-d', type=str, default='causal',\n",
        "                        help='for models with both masked and causal versions, determine which to use (default is masked)')\n",
        "    parser.add_argument('--model', '-m', type=str, default=\"gpt2-large\",\n",
        "                        help='select a model to use')\n",
        "    parser.add_argument('--model_list', '-mm', type=str, default=None,\n",
        "                        help='path to file with a list of models to run')\n",
        "    parser.add_argument('--task', '-t', type=str, default=\"surprisal\",\n",
        "                        help='metric to caclulate')\n",
        "    parser.add_argument('--task_list', '-tt', type=str, default=None,\n",
        "                        help='path to file with list of metrics to caclulate')\n",
        "    parser.add_argument('--following_context', '-f', action=\"store_true\", default=False,\n",
        "                        help='whether or not consider the following context with masked language models (default is False)')\n",
        "    parser.add_argument('--use_cpu', '-cpu', action=\"store_true\", default=False,\n",
        "                        help='use CPU for models even if CUDA is available')\n",
        "\n",
        "    # Create an argparse.Namespace object with the desired arguments\n",
        "    args = argparse.Namespace(\n",
        "        stimuli=\"/content/drive/MyDrive/PsychFormers/Stimuli.txt\",\n",
        "        stimuli_list=None,  # Or provide a path if needed\n",
        "        output_directory='/content/drive/MyDrive/PsychFormers/output',\n",
        "        primary_decoder=\"causal\",\n",
        "        model=\"gpt2-large\",\n",
        "        model_list=None,  # Or provide a path if needed\n",
        "        task=\"surprisal\",\n",
        "        task_list=None,  # Or provide a path if needed\n",
        "        following_context=False,\n",
        "        use_cpu=False\n",
        "    )\n",
        "\n",
        "    return args\n",
        "\n",
        "def process_args(args):\n",
        "    try:\n",
        "        output_directory = args.output_directory\n",
        "    except:\n",
        "        print(\"Error: Please specify a valid output directory.\")\n",
        "\n",
        "    if not os.path.exists(output_directory):\n",
        "        try:\n",
        "            os.makedirs(output_directory)\n",
        "        except:\n",
        "            print(\"Error: Cannot create output directory (Note: output directory does not already exist).\")\n",
        "\n",
        "    try:\n",
        "        primary_decoder = args.primary_decoder\n",
        "        assert primary_decoder==\"causal\" or primary_decoder==\"masked\"\n",
        "    except:\n",
        "        print(\"Error: Please select either 'causal' or 'masked' for primary decoder argument.\")\n",
        "\n",
        "    try:\n",
        "        include_following_context = args.following_context\n",
        "        assert type(include_following_context)==bool\n",
        "    except:\n",
        "        print(\"Error: 'following_context' argument must be Boolean.\")\n",
        "\n",
        "    try:\n",
        "        cpu = args.use_cpu\n",
        "        assert type(cpu)==bool\n",
        "    except:\n",
        "        print(\"Error: 'use_cpu' argument must be Boolean.\")\n",
        "\n",
        "    if args.model_list:\n",
        "        try:\n",
        "            assert os.path.exists(args.model_list)\n",
        "            with open(args.model_list, \"r\") as f:\n",
        "                model_list = f.read().splitlines()\n",
        "        except:\n",
        "            print(\"Error: 'model_list' argument does not have a valid path. Trying to use individual specified model.\")\n",
        "            try:\n",
        "                assert args.model\n",
        "                model_list = [args.model]\n",
        "            except:\n",
        "                print(\"Error: No model specified\")\n",
        "    else:\n",
        "        try:\n",
        "            assert args.model\n",
        "            model_list = [args.model]\n",
        "        except:\n",
        "            print(\"Error: No model specified\")\n",
        "\n",
        "\n",
        "\n",
        "    if args.task_list:\n",
        "        try:\n",
        "            assert os.path.exists(args.task_list)\n",
        "            with open(args.task_list, \"r\") as f:\n",
        "                metric_list = f.read().splitlines()\n",
        "        except:\n",
        "            print(\"Error: 'metric_list' argument does not have a valid path. Trying to use individual specified metric.\")\n",
        "            try:\n",
        "                assert args.task\n",
        "                metric_list = [args.task]\n",
        "            except:\n",
        "                print(\"Error: No metric specified\")\n",
        "    else:\n",
        "        try:\n",
        "            assert args.task\n",
        "            metric_list = [args.task]\n",
        "        except:\n",
        "            print(\"Error: No metric specified\")\n",
        "\n",
        "\n",
        "    if args.stimuli_list:\n",
        "        try:\n",
        "            assert os.path.exists(args.stimuli_list)\n",
        "            with open(args.stimuli_list, \"r\") as f:\n",
        "                stimulus_file_list = f.read().splitlines()\n",
        "        except:\n",
        "            print(\"Error: 'stimuli_list' argument does not have a valid path. Trying to use individual stimulus set.\")\n",
        "            try:\n",
        "                assert args.stimuli\n",
        "                stimulus_file_list = [args.stimuli]\n",
        "            except:\n",
        "                print(\"Error: No stimuli specified\")\n",
        "    else:\n",
        "        try:\n",
        "            assert args.stimuli\n",
        "            stimulus_file_list = [args.stimuli]\n",
        "        except:\n",
        "            print(\"Error: No stimuli specified\")\n",
        "\n",
        "    return(output_directory,primary_decoder,include_following_context,model_list,metric_list,stimulus_file_list,cpu)\n",
        "\n",
        "def create_and_run_models(model_list,stimulus_file_list,metric_list,primary_decoder,output_directory,include_following_context,cpu):\n",
        "    if primary_decoder == \"masked\":\n",
        "        for model_name in model_list:\n",
        "\n",
        "            model_name_cleaned = model_name.replace(\"/\",\"-\")\n",
        "\n",
        "            if 'tokenizer' in locals():\n",
        "                del(tokenizer)\n",
        "\n",
        "            if 'model' in locals():\n",
        "                del(model)\n",
        "\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "                if (not tokenizer.bos_token) and (tokenizer.cls_token):\n",
        "                    tokenizer.bos_token = tokenizer.cls_token\n",
        "                if (not tokenizer.eos_token) and (tokenizer.sep_token):\n",
        "                    tokenizer.eos_token = tokenizer.sep_token\n",
        "\n",
        "                tokenizer.add_tokens([\"[!StimulusMarker!]\",\" [!StimulusMarker!]\"])\n",
        "\n",
        "            except:\n",
        "                print(\"Cannot create a tokenizer for model {0}\".format(model_name))\n",
        "\n",
        "            try:\n",
        "                model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "                model_type = \"masked\"\n",
        "            except:\n",
        "                try:\n",
        "                    model = AutoModelForCausalLM.from_pretrained(model_name,is_decoder=True)\n",
        "                    model_type = \"causal\"\n",
        "                except:\n",
        "                    print(\"Model {0} is not a masked or causal language model. This is not supported\".format(model_name))\n",
        "            try:\n",
        "                assert model and tokenizer\n",
        "                if model and tokenizer:\n",
        "                    try:\n",
        "                        if model_type==\"causal\":\n",
        "                            process_stims_causal(model.to(\"cuda\" if (torch.cuda.is_available() and not cpu) else \"cpu\"),tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context)\n",
        "                        elif model_type==\"masked\":\n",
        "                            process_stims_masked(model.to(\"cuda\" if (torch.cuda.is_available() and not cpu) else \"cpu\"),tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context)\n",
        "                    except:\n",
        "                        print(\"Cannot run either a masked or causal form of {0}\".format(model_name))\n",
        "            except:\n",
        "                print(\"Cannot run experiment without both a tokenizer for and a causal or masked form of {0}\".format(model_name))\n",
        "\n",
        "    elif primary_decoder == \"causal\":\n",
        "        for model_name in model_list:\n",
        "\n",
        "            model_name_cleaned = model_name.replace(\"/\",\"-\")\n",
        "\n",
        "            if 'tokenizer' in locals():\n",
        "                del(tokenizer)\n",
        "\n",
        "            if 'model' in locals():\n",
        "                del(model)\n",
        "\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "                if (not tokenizer.bos_token) and (tokenizer.cls_token):\n",
        "                    tokenizer.bos_token = tokenizer.cls_token\n",
        "                if (not tokenizer.eos_token) and (tokenizer.sep_token):\n",
        "                    tokenizer.eos_token = tokenizer.sep_token\n",
        "\n",
        "                tokenizer.add_tokens([\"[!StimulusMarker!]\",\" [!StimulusMarker!]\"])\n",
        "\n",
        "            except:\n",
        "                print(\"Cannot create a tokenizer for model {0}\".format(model_name))\n",
        "\n",
        "            try:\n",
        "                model = AutoModelForCausalLM.from_pretrained(model_name,is_decoder=True)\n",
        "                model_type = \"causal\"\n",
        "                if \"Masked\" in model.config.architectures[0]:\n",
        "                    model_type = \"causal_mask\"\n",
        "            except:\n",
        "                try:\n",
        "                    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "                    model_type = \"masked\"\n",
        "                except:\n",
        "                    print(\"Model {0} is not a causal or masked language model. This is not supported\".format(model_name))\n",
        "            try:\n",
        "                assert model and tokenizer\n",
        "                if model and tokenizer:\n",
        "                    try:\n",
        "                        if model_type==\"causal\":\n",
        "                            process_stims_causal(model.to(\"cuda\" if (torch.cuda.is_available() and not cpu) else \"cpu\"),tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context)\n",
        "                        elif model_type==\"masked\":\n",
        "                            process_stims_masked(model.to(\"cuda\" if (torch.cuda.is_available() and not cpu) else \"cpu\"),tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context)\n",
        "                        elif model_type==\"causal_mask\":\n",
        "                            process_stims_causal_mask(model.to(\"cuda\" if (torch.cuda.is_available() and not cpu) else \"cpu\"),tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context)\n",
        "\n",
        "                    except:\n",
        "                        print(\"Cannot run either a causal or masked form of {0}\".format(model_name))\n",
        "            except:\n",
        "                print(\"Cannot run experiment without both a tokenizer for and a causal or masked form of {0}\".format(model_name))\n",
        "\n",
        "\n",
        "def process_stims_causal(model,tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context):\n",
        "    for i in range(len(stimulus_file_list)):\n",
        "        stimuli_name = stimulus_file_list[i].split('/')[-1].split('.')[0]\n",
        "\n",
        "        if \"surprisal\" in metric_list:\n",
        "            filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".causal.output\"\n",
        "            with open(filename,\"w\") as f:\n",
        "                f.write(\"FullSentence\\tSentence\\tTargetWords\\tSurprisal\\tNumTokens\\n\")\n",
        "\n",
        "        with open(stimulus_file_list[i],'r') as f:\n",
        "            stimulus_list = f.read().splitlines()\n",
        "        for j in range(len(stimulus_list)):\n",
        "            try:\n",
        "                stimulus = stimulus_list[j]\n",
        "                stimulus_spaces = stimulus.replace(\"*\", \"[!StimulusMarker!]\")\n",
        "                stimulus_spaces = stimulus_spaces.replace(\" [!StimulusMarker!]\", \"[!StimulusMarker!] \")\n",
        "                encoded_stimulus = tokenizer.encode(stimulus_spaces)\n",
        "\n",
        "                if (len(tokenizer.tokenize(\"a[!StimulusMarker!]\"))==2):\n",
        "                    dummy_var_idxs = np.where((np.array(encoded_stimulus)==tokenizer.encode(\"[!StimulusMarker!]\")[-1]) | (np.array(encoded_stimulus)==tokenizer.encode(\"a[!StimulusMarker!]\")[-1]))[0]\n",
        "                    preceding_context = encoded_stimulus[:dummy_var_idxs[0]]\n",
        "                    if (len(preceding_context)==0) or (not ((preceding_context[0]==tokenizer.bos_token_id) or (preceding_context[0]==tokenizer.eos_token_id))):\n",
        "                        preceding_context = [tokenizer.bos_token_id] + preceding_context\n",
        "                    target_words = encoded_stimulus[dummy_var_idxs[0]+1:dummy_var_idxs[1]]\n",
        "                    following_words = encoded_stimulus[dummy_var_idxs[1]+1:]\n",
        "\n",
        "                    if \"[!StimulusMarker!] \" in stimulus_spaces and tokenizer.decode(target_words)[0]!=\" \":\n",
        "                        target_words_decoded = \" \" +tokenizer.decode(target_words)\n",
        "                        target_words = tokenizer.encode(target_words_decoded)\n",
        "                        if tokenizer.bos_token_id  in target_words:\n",
        "                            target_words.remove(tokenizer.bos_token_id)\n",
        "                        if tokenizer.eos_token_id  in target_words:\n",
        "                            target_words.remove(tokenizer.eos_token_id)\n",
        "\n",
        "                    if \"surprisal\" in metric_list:\n",
        "                        get_surprisal_causal(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,stimulus)\n",
        "            except:\n",
        "                print(\"Problem with stimulus on line {0}: {1}\\n\".format(str(j+1),stimulus_list[j]))\n",
        "\n",
        "\n",
        "def get_surprisal_causal(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,stimulus):\n",
        "    filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".causal.output\"\n",
        "    current_context = copy.deepcopy(preceding_context)\n",
        "    all_probabilities = []\n",
        "    for i in range(len(target_words)):\n",
        "        current_target = target_words[i]\n",
        "        input = torch.LongTensor([current_context]).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            next_token_logits = model(input, return_dict=True).logits[:, -1, :]\n",
        "        probs = F.softmax(next_token_logits,dim=-1)\n",
        "        probability = probs[0,current_target]\n",
        "        current_context.append(current_target)\n",
        "        all_probabilities.append(probability.item())\n",
        "    all_probabilities = np.array(all_probabilities)\n",
        "    num_tokens = len(all_probabilities)\n",
        "    sum_surprisal = np.sum(-np.log2(all_probabilities))\n",
        "    sentence = tokenizer.decode(preceding_context[1:]+target_words)\n",
        "    full_sentence = tokenizer.decode(preceding_context[1:]+target_words+following_words)\n",
        "    target_string = tokenizer.decode(target_words)\n",
        "    with open(filename,\"a\") as f:\n",
        "        f.write(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\n\".format(\n",
        "            stimulus.replace(\"*\",\"\"),\n",
        "            sentence,\n",
        "            target_string,\n",
        "            sum_surprisal,\n",
        "            num_tokens\n",
        "        ))\n",
        "\n",
        "\n",
        "def process_stims_masked(model,tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context):\n",
        "    for i in range(len(stimulus_file_list)):\n",
        "        stimuli_name = stimulus_file_list[i].split('/')[-1].split('.')[0]\n",
        "\n",
        "        if \"surprisal\" in metric_list:\n",
        "            filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".masked.output\"\n",
        "            with open(filename,\"w\") as f:\n",
        "                f.write(\"FullSentence\\tSentence\\tTargetWords\\tSurprisal\\tNumTokens\\n\")\n",
        "\n",
        "        with open(stimulus_file_list[i],'r') as f:\n",
        "            stimulus_list = f.read().splitlines()\n",
        "        for j in range(len(stimulus_list)):\n",
        "            try:\n",
        "                stimulus = stimulus_list[j]\n",
        "                stimulus_spaces = stimulus.replace(\"*\", \"[!StimulusMarker!]\")\n",
        "                if (tokenizer.tokenize(\" a\")[0][0]==tokenizer.tokenize(\" b\")[0][0]) and (tokenizer.tokenize(\"a\")[0][0]!=tokenizer.tokenize(\"b\")[0][0]):\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\" [!StimulusMarker!]\", \"[!StimulusMarker!] \")\n",
        "                else:\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\"[!StimulusMarker!]\", \"[!StimulusMarker!] \")\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\" [!StimulusMarker!]\", \"[!StimulusMarker!]\")\n",
        "                encoded_stimulus = tokenizer.encode(stimulus_spaces)[1:-1]\n",
        "\n",
        "                if (len(tokenizer.tokenize(\"a[!StimulusMarker!]\"))==2):\n",
        "                    dummy_var_idxs = np.where((np.array(encoded_stimulus)==tokenizer.encode(\"[!StimulusMarker!]\")[-2]) | (np.array(encoded_stimulus)==tokenizer.encode(\"a[!StimulusMarker!]\")[-2]))[0]\n",
        "                    preceding_context = encoded_stimulus[:dummy_var_idxs[0]]\n",
        "                    if (len(preceding_context)==0) or (not preceding_context[0]==tokenizer.bos_token_id):\n",
        "                        preceding_context = [tokenizer.bos_token_id] + preceding_context\n",
        "                    target_words = encoded_stimulus[dummy_var_idxs[0]+1:dummy_var_idxs[1]]\n",
        "                    following_words = encoded_stimulus[dummy_var_idxs[1]+1:]\n",
        "                    if \"surprisal\" in metric_list:\n",
        "                        get_surprisal_masked(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,include_following_context,stimulus)\n",
        "            except:\n",
        "                print(\"Problem with stimulus on line {0}: {1}\\n\".format(str(j+1),stimulus_list[j]))\n",
        "\n",
        "def get_surprisal_masked(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,include_following_context,stimulus):\n",
        "    filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".masked.output\"\n",
        "    current_context = copy.deepcopy(preceding_context)\n",
        "    all_probabilities = []\n",
        "    for i in range(len(target_words)):\n",
        "        current_target = target_words[i]\n",
        "        context_plus_mask = current_context + [tokenizer.mask_token_id]\n",
        "        if include_following_context==True:\n",
        "            context_plus_mask = context_plus_mask + following_words\n",
        "        model_input_list = context_plus_mask+[tokenizer.eos_token_id]\n",
        "        mask_idx = model_input_list.index(tokenizer.mask_token_id)\n",
        "        input = torch.LongTensor([model_input_list]).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            next_token_logits = model(input, return_dict=True).logits[:, mask_idx, :]\n",
        "        probs = F.softmax(next_token_logits,dim=-1)\n",
        "        probability = probs[0,current_target]\n",
        "        current_context.append(current_target)\n",
        "        all_probabilities.append(probability.item())\n",
        "    all_probabilities = np.array(all_probabilities)\n",
        "    num_tokens = len(all_probabilities)\n",
        "    sum_surprisal = np.sum(-np.log2(all_probabilities))\n",
        "    sentence = tokenizer.decode(preceding_context[1:]+target_words)\n",
        "    full_sentence = tokenizer.decode(preceding_context[1:]+target_words+following_words)\n",
        "    target_string = tokenizer.decode(target_words)\n",
        "    with open(filename,\"a\") as f:\n",
        "        f.write(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\n\".format(\n",
        "            stimulus.replace(\"*\",\"\"),\n",
        "            sentence,\n",
        "            target_string,\n",
        "            sum_surprisal,\n",
        "            num_tokens\n",
        "        ))\n",
        "\n",
        "def process_stims_causal_mask(model,tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context):\n",
        "    for i in range(len(stimulus_file_list)):\n",
        "        stimuli_name = stimulus_file_list[i].split('/')[-1].split('.')[0]\n",
        "\n",
        "        if \"surprisal\" in metric_list:\n",
        "            filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".causal_mask.output\"\n",
        "            with open(filename,\"w\") as f:\n",
        "                f.write(\"FullSentence\\tSentence\\tTargetWords\\tSurprisal\\tNumTokens\\n\")\n",
        "\n",
        "        with open(stimulus_file_list[i],'r') as f:\n",
        "            stimulus_list = f.read().splitlines()\n",
        "        for j in range(len(stimulus_list)):\n",
        "            try:\n",
        "                stimulus = stimulus_list[j]\n",
        "                stimulus_spaces = stimulus.replace(\"*\", \"[!StimulusMarker!]\")\n",
        "                if (tokenizer.tokenize(\" a\")[0][0]==tokenizer.tokenize(\" b\")[0][0]) and (tokenizer.tokenize(\"a\")[0][0]!=tokenizer.tokenize(\"b\")[0][0]):\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\" [!StimulusMarker!]\", \"[!StimulusMarker!] \")\n",
        "                else:\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\"[!StimulusMarker!]\", \"[!StimulusMarker!] \")\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\" [!StimulusMarker!]\", \"[!StimulusMarker!]\")\n",
        "                encoded_stimulus = tokenizer.encode(stimulus_spaces)[1:-1]\n",
        "\n",
        "                if (len(tokenizer.tokenize(\"a[!StimulusMarker!]\"))==2):\n",
        "                    dummy_var_idxs = np.where((np.array(encoded_stimulus)==tokenizer.encode(\"[!StimulusMarker!]\")[-2]) | (np.array(encoded_stimulus)==tokenizer.encode(\"a[!StimulusMarker!]\")[-2]))[0]\n",
        "                    preceding_context = encoded_stimulus[:dummy_var_idxs[0]]\n",
        "                    if (len(preceding_context)==0) or (not preceding_context[0]==tokenizer.bos_token_id):\n",
        "                        preceding_context = [tokenizer.bos_token_id] + preceding_context\n",
        "                    target_words = encoded_stimulus[dummy_var_idxs[0]+1:dummy_var_idxs[1]]\n",
        "                    following_words = encoded_stimulus[dummy_var_idxs[1]+1:]\n",
        "\n",
        "                    if \"surprisal\" in metric_list:\n",
        "                        get_surprisal_causal_mask(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,include_following_context,stimulus)\n",
        "            except:\n",
        "                print(\"Problem with stimulus on line {0}: {1}\\n\".format(str(j+1),stimulus_list[j]))\n",
        "\n",
        "def get_surprisal_causal_mask(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,include_following_context,stimulus):\n",
        "    filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".causal_mask.output\"\n",
        "    current_context = copy.deepcopy(preceding_context)\n",
        "    all_probabilities = []\n",
        "    for i in range(len(target_words)):\n",
        "        current_target = target_words[i]\n",
        "        context_plus_mask = current_context + [tokenizer.mask_token_id]\n",
        "        if include_following_context==True:\n",
        "            context_plus_mask = context_plus_mask + following_words\n",
        "        model_input_list = context_plus_mask+[tokenizer.eos_token_id]\n",
        "        mask_idx = model_input_list.index(tokenizer.mask_token_id)\n",
        "        input = torch.LongTensor([model_input_list]).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            next_token_logits = model(input, return_dict=True).logits[:, mask_idx, :]\n",
        "        probs = F.softmax(next_token_logits,dim=-1)\n",
        "        probability = probs[0,current_target]\n",
        "        current_context.append(current_target)\n",
        "        all_probabilities.append(probability.item())\n",
        "    all_probabilities = np.array(all_probabilities)\n",
        "    num_tokens = len(all_probabilities)\n",
        "    sum_surprisal = np.sum(-np.log2(all_probabilities))\n",
        "    sentence = tokenizer.decode(preceding_context[1:]+target_words)\n",
        "    full_sentence = tokenizer.decode(preceding_context[1:]+target_words+following_words)\n",
        "    target_string = tokenizer.decode(target_words)\n",
        "    with open(filename,\"a\") as f:\n",
        "        f.write(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\n\".format(\n",
        "            stimulus.replace(\"*\",\"\"),\n",
        "            sentence,\n",
        "            target_string,\n",
        "            sum_surprisal,\n",
        "            num_tokens\n",
        "        ))\n",
        "\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    args = parse_args()\n",
        "    output_directory,primary_decoder,include_following_context,model_list,metric_list,stimulus_file_list,cpu = process_args(args)\n",
        "    create_and_run_models(model_list,stimulus_file_list,metric_list,primary_decoder,output_directory,include_following_context,cpu)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "H5RWeJre_XB8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deepseek R1"
      ],
      "metadata": {
        "id": "4kHGfM6euUxX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hJaJHVasuWS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import argparse\n",
        "from transformers import AutoTokenizer,AutoModelForCausalLM,AutoModelForMaskedLM\n",
        "from torch.nn import functional as F\n",
        "import torch\n",
        "import numpy as np\n",
        "import copy\n",
        "\n",
        "\n",
        "\n",
        "def parse_args():\n",
        "    parser = argparse.ArgumentParser(description='Calculates surprisal and other metrics...')\n",
        "\n",
        "    parser.add_argument('--stimuli', '-i', type=str, default=\"/content/drive/MyDrive/PsychFormers/interpreted_stimuli.txt\",\n",
        "                        help='stimuli to test')\n",
        "    parser.add_argument('--stimuli_list', '-ii', type=str, default=None,\n",
        "                        help='path to file containing list of stimulus files to test')\n",
        "    parser.add_argument('--output_directory', '-o', type=str, default='/content/drive/MyDrive/PsychFormers/interpreted stimuli output',\n",
        "                        help='output directory')\n",
        "    parser.add_argument('--primary_decoder', '-d', type=str, default='causal',\n",
        "                        help='for models with both masked and causal versions, determine which to use (default is masked)')\n",
        "    parser.add_argument('--model', '-m', type=str, default=\"IDEA-CCNL/Wenzhong-GPT2-3.5B\",\n",
        "                        help='select a model to use')\n",
        "    parser.add_argument('--model_list', '-mm', type=str, default=None,\n",
        "                        help='path to file with a list of models to run')\n",
        "    parser.add_argument('--task', '-t', type=str, default=\"surprisal\",\n",
        "                        help='metric to caclulate')\n",
        "    parser.add_argument('--task_list', '-tt', type=str, default=None,\n",
        "                        help='path to file with list of metrics to caclulate')\n",
        "    parser.add_argument('--following_context', '-f', action=\"store_true\", default=False,\n",
        "                        help='whether or not consider the following context with masked language models (default is False)')\n",
        "    parser.add_argument('--use_cpu', '-cpu', action=\"store_true\", default=True,\n",
        "                        help='use CPU for models even if CUDA is available')\n",
        "\n",
        "    # Create an argparse.Namespace object with the desired arguments\n",
        "    args = argparse.Namespace(\n",
        "        stimuli=\"/content/drive/MyDrive/PsychFormers/interpreted_stimuli.txt\",\n",
        "        stimuli_list=None,  # Or provide a path if needed\n",
        "        output_directory='/content/drive/MyDrive/PsychFormers/interpreted stimuli output',\n",
        "        primary_decoder=\"causal\",\n",
        "        model=\"IDEA-CCNL/Wenzhong-GPT2-3.5B\",\n",
        "        model_list=None,  # Or provide a path if needed\n",
        "        task=\"surprisal\",\n",
        "        task_list=None,  # Or provide a path if needed\n",
        "        following_context=False,\n",
        "        use_cpu=True\n",
        "    )\n",
        "\n",
        "    return args\n",
        "\n",
        "def process_args(args):\n",
        "    try:\n",
        "        output_directory = args.output_directory\n",
        "    except:\n",
        "        print(\"Error: Please specify a valid output directory.\")\n",
        "\n",
        "    if not os.path.exists(output_directory):\n",
        "        try:\n",
        "            os.makedirs(output_directory)\n",
        "        except:\n",
        "            print(\"Error: Cannot create output directory (Note: output directory does not already exist).\")\n",
        "\n",
        "    try:\n",
        "        primary_decoder = args.primary_decoder\n",
        "        assert primary_decoder==\"causal\" or primary_decoder==\"masked\"\n",
        "    except:\n",
        "        print(\"Error: Please select either 'causal' or 'masked' for primary decoder argument.\")\n",
        "\n",
        "    try:\n",
        "        include_following_context = args.following_context\n",
        "        assert type(include_following_context)==bool\n",
        "    except:\n",
        "        print(\"Error: 'following_context' argument must be Boolean.\")\n",
        "\n",
        "    try:\n",
        "        cpu = args.use_cpu\n",
        "        assert type(cpu)==bool\n",
        "    except:\n",
        "        print(\"Error: 'use_cpu' argument must be Boolean.\")\n",
        "\n",
        "    if args.model_list:\n",
        "        try:\n",
        "            assert os.path.exists(args.model_list)\n",
        "            with open(args.model_list, \"r\") as f:\n",
        "                model_list = f.read().splitlines()\n",
        "        except:\n",
        "            print(\"Error: 'model_list' argument does not have a valid path. Trying to use individual specified model.\")\n",
        "            try:\n",
        "                assert args.model\n",
        "                model_list = [args.model]\n",
        "            except:\n",
        "                print(\"Error: No model specified\")\n",
        "    else:\n",
        "        try:\n",
        "            assert args.model\n",
        "            model_list = [args.model]\n",
        "        except:\n",
        "            print(\"Error: No model specified\")\n",
        "\n",
        "\n",
        "\n",
        "    if args.task_list:\n",
        "        try:\n",
        "            assert os.path.exists(args.task_list)\n",
        "            with open(args.task_list, \"r\") as f:\n",
        "                metric_list = f.read().splitlines()\n",
        "        except:\n",
        "            print(\"Error: 'metric_list' argument does not have a valid path. Trying to use individual specified metric.\")\n",
        "            try:\n",
        "                assert args.task\n",
        "                metric_list = [args.task]\n",
        "            except:\n",
        "                print(\"Error: No metric specified\")\n",
        "    else:\n",
        "        try:\n",
        "            assert args.task\n",
        "            metric_list = [args.task]\n",
        "        except:\n",
        "            print(\"Error: No metric specified\")\n",
        "\n",
        "\n",
        "    if args.stimuli_list:\n",
        "        try:\n",
        "            assert os.path.exists(args.stimuli_list)\n",
        "            with open(args.stimuli_list, \"r\") as f:\n",
        "                stimulus_file_list = f.read().splitlines()\n",
        "        except:\n",
        "            print(\"Error: 'stimuli_list' argument does not have a valid path. Trying to use individual stimulus set.\")\n",
        "            try:\n",
        "                assert args.stimuli\n",
        "                stimulus_file_list = [args.stimuli]\n",
        "            except:\n",
        "                print(\"Error: No stimuli specified\")\n",
        "    else:\n",
        "        try:\n",
        "            assert args.stimuli\n",
        "            stimulus_file_list = [args.stimuli]\n",
        "        except:\n",
        "            print(\"Error: No stimuli specified\")\n",
        "\n",
        "    return(output_directory,primary_decoder,include_following_context,model_list,metric_list,stimulus_file_list,cpu)\n",
        "\n",
        "def create_and_run_models(model_list,stimulus_file_list,metric_list,primary_decoder,output_directory,include_following_context,cpu):\n",
        "    if primary_decoder == \"masked\":\n",
        "        for model_name in model_list:\n",
        "\n",
        "            model_name_cleaned = model_name.replace(\"/\",\"-\")\n",
        "\n",
        "            if 'tokenizer' in locals():\n",
        "                del(tokenizer)\n",
        "\n",
        "            if 'model' in locals():\n",
        "                del(model)\n",
        "\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "                if (not tokenizer.bos_token) and (tokenizer.cls_token):\n",
        "                    tokenizer.bos_token = tokenizer.cls_token\n",
        "                if (not tokenizer.eos_token) and (tokenizer.sep_token):\n",
        "                    tokenizer.eos_token = tokenizer.sep_token\n",
        "\n",
        "                tokenizer.add_tokens([\"[!StimulusMarker!]\",\" [!StimulusMarker!]\"])\n",
        "\n",
        "            except:\n",
        "                print(\"Cannot create a tokenizer for model {0}\".format(model_name))\n",
        "\n",
        "            try:\n",
        "                model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "                model_type = \"masked\"\n",
        "            except:\n",
        "                try:\n",
        "                    model = AutoModelForCausalLM.from_pretrained(model_name,is_decoder=True)\n",
        "                    model_type = \"causal\"\n",
        "                except:\n",
        "                    print(\"Model {0} is not a masked or causal language model. This is not supported\".format(model_name))\n",
        "            try:\n",
        "                assert model and tokenizer\n",
        "                if model and tokenizer:\n",
        "                    try:\n",
        "                        if model_type==\"causal\":\n",
        "                            process_stims_causal(model.to(\"cuda\" if (torch.cuda.is_available() and not cpu) else \"cpu\"),tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context)\n",
        "                        elif model_type==\"masked\":\n",
        "                            process_stims_masked(model.to(\"cuda\" if (torch.cuda.is_available() and not cpu) else \"cpu\"),tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context)\n",
        "                    except:\n",
        "                        print(\"Cannot run either a masked or causal form of {0}\".format(model_name))\n",
        "            except:\n",
        "                print(\"Cannot run experiment without both a tokenizer for and a causal or masked form of {0}\".format(model_name))\n",
        "\n",
        "    elif primary_decoder == \"causal\":\n",
        "        for model_name in model_list:\n",
        "\n",
        "            model_name_cleaned = model_name.replace(\"/\",\"-\")\n",
        "\n",
        "            if 'tokenizer' in locals():\n",
        "                del(tokenizer)\n",
        "\n",
        "            if 'model' in locals():\n",
        "                del(model)\n",
        "\n",
        "            try:\n",
        "                tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "                if (not tokenizer.bos_token) and (tokenizer.cls_token):\n",
        "                    tokenizer.bos_token = tokenizer.cls_token\n",
        "                if (not tokenizer.eos_token) and (tokenizer.sep_token):\n",
        "                    tokenizer.eos_token = tokenizer.sep_token\n",
        "\n",
        "                tokenizer.add_tokens([\"[!StimulusMarker!]\",\" [!StimulusMarker!]\"])\n",
        "\n",
        "            except:\n",
        "                print(\"Cannot create a tokenizer for model {0}\".format(model_name))\n",
        "\n",
        "            try:\n",
        "                model = AutoModelForCausalLM.from_pretrained(model_name,is_decoder=True)\n",
        "                model_type = \"causal\"\n",
        "                if \"Masked\" in model.config.architectures[0]:\n",
        "                    model_type = \"causal_mask\"\n",
        "            except:\n",
        "                try:\n",
        "                    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "                    model_type = \"masked\"\n",
        "                except:\n",
        "                    print(\"Model {0} is not a causal or masked language model. This is not supported\".format(model_name))\n",
        "            try:\n",
        "                assert model and tokenizer\n",
        "                if model and tokenizer:\n",
        "                    try:\n",
        "                        if model_type==\"causal\":\n",
        "                            process_stims_causal(model.to(\"cuda\" if (torch.cuda.is_available() and not cpu) else \"cpu\"),tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context)\n",
        "                        elif model_type==\"masked\":\n",
        "                            process_stims_masked(model.to(\"cuda\" if (torch.cuda.is_available() and not cpu) else \"cpu\"),tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context)\n",
        "                        elif model_type==\"causal_mask\":\n",
        "                            process_stims_causal_mask(model.to(\"cuda\" if (torch.cuda.is_available() and not cpu) else \"cpu\"),tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context)\n",
        "\n",
        "                    except:\n",
        "                        print(\"Cannot run either a causal or masked form of {0}\".format(model_name))\n",
        "            except:\n",
        "                print(\"Cannot run experiment without both a tokenizer for and a causal or masked form of {0}\".format(model_name))\n",
        "\n",
        "\n",
        "def process_stims_causal(model,tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context):\n",
        "    for i in range(len(stimulus_file_list)):\n",
        "        stimuli_name = stimulus_file_list[i].split('/')[-1].split('.')[0]\n",
        "\n",
        "        if \"surprisal\" in metric_list:\n",
        "            filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".causal.output\"\n",
        "            with open(filename,\"w\") as f:\n",
        "                f.write(\"FullSentence\\tSentence\\tTargetWords\\tSurprisal\\tNumTokens\\n\")\n",
        "\n",
        "        with open(stimulus_file_list[i],'r') as f:\n",
        "            stimulus_list = f.read().splitlines()\n",
        "        for j in range(len(stimulus_list)):\n",
        "            try:\n",
        "                stimulus = stimulus_list[j]\n",
        "                stimulus_spaces = stimulus.replace(\"*\", \"[!StimulusMarker!]\")\n",
        "                stimulus_spaces = stimulus_spaces.replace(\" [!StimulusMarker!]\", \"[!StimulusMarker!] \")\n",
        "                encoded_stimulus = tokenizer.encode(stimulus_spaces)\n",
        "\n",
        "                if (len(tokenizer.tokenize(\"a[!StimulusMarker!]\"))==2):\n",
        "                    dummy_var_idxs = np.where((np.array(encoded_stimulus)==tokenizer.encode(\"[!StimulusMarker!]\")[-1]) | (np.array(encoded_stimulus)==tokenizer.encode(\"a[!StimulusMarker!]\")[-1]))[0]\n",
        "                    preceding_context = encoded_stimulus[:dummy_var_idxs[0]]\n",
        "                    if (len(preceding_context)==0) or (not ((preceding_context[0]==tokenizer.bos_token_id) or (preceding_context[0]==tokenizer.eos_token_id))):\n",
        "                        preceding_context = [tokenizer.bos_token_id] + preceding_context\n",
        "                    target_words = encoded_stimulus[dummy_var_idxs[0]+1:dummy_var_idxs[1]]\n",
        "                    following_words = encoded_stimulus[dummy_var_idxs[1]+1:]\n",
        "\n",
        "                    if \"[!StimulusMarker!] \" in stimulus_spaces and tokenizer.decode(target_words)[0]!=\" \":\n",
        "                        target_words_decoded = \" \" +tokenizer.decode(target_words)\n",
        "                        target_words = tokenizer.encode(target_words_decoded)\n",
        "                        if tokenizer.bos_token_id  in target_words:\n",
        "                            target_words.remove(tokenizer.bos_token_id)\n",
        "                        if tokenizer.eos_token_id  in target_words:\n",
        "                            target_words.remove(tokenizer.eos_token_id)\n",
        "\n",
        "                    if \"surprisal\" in metric_list:\n",
        "                        get_surprisal_causal(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,stimulus)\n",
        "            except:\n",
        "                print(\"Problem with stimulus on line {0}: {1}\\n\".format(str(j+1),stimulus_list[j]))\n",
        "\n",
        "\n",
        "def get_surprisal_causal(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,stimulus):\n",
        "    filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".causal.output\"\n",
        "    current_context = copy.deepcopy(preceding_context)\n",
        "    all_probabilities = []\n",
        "    for i in range(len(target_words)):\n",
        "        current_target = target_words[i]\n",
        "        input = torch.LongTensor([current_context]).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            next_token_logits = model(input, return_dict=True).logits[:, -1, :]\n",
        "        probs = F.softmax(next_token_logits,dim=-1)\n",
        "        probability = probs[0,current_target]\n",
        "        current_context.append(current_target)\n",
        "        all_probabilities.append(probability.item())\n",
        "    all_probabilities = np.array(all_probabilities)\n",
        "    num_tokens = len(all_probabilities)\n",
        "    sum_surprisal = np.sum(-np.log2(all_probabilities))\n",
        "    sentence = tokenizer.decode(preceding_context[1:]+target_words)\n",
        "    full_sentence = tokenizer.decode(preceding_context[1:]+target_words+following_words)\n",
        "    target_string = tokenizer.decode(target_words)\n",
        "    with open(filename,\"a\") as f:\n",
        "        f.write(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\n\".format(\n",
        "            stimulus.replace(\"*\",\"\"),\n",
        "            sentence,\n",
        "            target_string,\n",
        "            sum_surprisal,\n",
        "            num_tokens\n",
        "        ))\n",
        "\n",
        "\n",
        "def process_stims_masked(model,tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context):\n",
        "    for i in range(len(stimulus_file_list)):\n",
        "        stimuli_name = stimulus_file_list[i].split('/')[-1].split('.')[0]\n",
        "\n",
        "        if \"surprisal\" in metric_list:\n",
        "            filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".masked.output\"\n",
        "            with open(filename,\"w\") as f:\n",
        "                f.write(\"FullSentence\\tSentence\\tTargetWords\\tSurprisal\\tNumTokens\\n\")\n",
        "\n",
        "        with open(stimulus_file_list[i],'r') as f:\n",
        "            stimulus_list = f.read().splitlines()\n",
        "        for j in range(len(stimulus_list)):\n",
        "            try:\n",
        "                stimulus = stimulus_list[j]\n",
        "                stimulus_spaces = stimulus.replace(\"*\", \"[!StimulusMarker!]\")\n",
        "                if (tokenizer.tokenize(\" a\")[0][0]==tokenizer.tokenize(\" b\")[0][0]) and (tokenizer.tokenize(\"a\")[0][0]!=tokenizer.tokenize(\"b\")[0][0]):\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\" [!StimulusMarker!]\", \"[!StimulusMarker!] \")\n",
        "                else:\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\"[!StimulusMarker!]\", \"[!StimulusMarker!] \")\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\" [!StimulusMarker!]\", \"[!StimulusMarker!]\")\n",
        "                encoded_stimulus = tokenizer.encode(stimulus_spaces)[1:-1]\n",
        "\n",
        "                if (len(tokenizer.tokenize(\"a[!StimulusMarker!]\"))==2):\n",
        "                    dummy_var_idxs = np.where((np.array(encoded_stimulus)==tokenizer.encode(\"[!StimulusMarker!]\")[-2]) | (np.array(encoded_stimulus)==tokenizer.encode(\"a[!StimulusMarker!]\")[-2]))[0]\n",
        "                    preceding_context = encoded_stimulus[:dummy_var_idxs[0]]\n",
        "                    if (len(preceding_context)==0) or (not preceding_context[0]==tokenizer.bos_token_id):\n",
        "                        preceding_context = [tokenizer.bos_token_id] + preceding_context\n",
        "                    target_words = encoded_stimulus[dummy_var_idxs[0]+1:dummy_var_idxs[1]]\n",
        "                    following_words = encoded_stimulus[dummy_var_idxs[1]+1:]\n",
        "                    if \"surprisal\" in metric_list:\n",
        "                        get_surprisal_masked(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,include_following_context,stimulus)\n",
        "            except:\n",
        "                print(\"Problem with stimulus on line {0}: {1}\\n\".format(str(j+1),stimulus_list[j]))\n",
        "\n",
        "def get_surprisal_masked(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,include_following_context,stimulus):\n",
        "    filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".masked.output\"\n",
        "    current_context = copy.deepcopy(preceding_context)\n",
        "    all_probabilities = []\n",
        "    for i in range(len(target_words)):\n",
        "        current_target = target_words[i]\n",
        "        context_plus_mask = current_context + [tokenizer.mask_token_id]\n",
        "        if include_following_context==True:\n",
        "            context_plus_mask = context_plus_mask + following_words\n",
        "        model_input_list = context_plus_mask+[tokenizer.eos_token_id]\n",
        "        mask_idx = model_input_list.index(tokenizer.mask_token_id)\n",
        "        input = torch.LongTensor([model_input_list]).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            next_token_logits = model(input, return_dict=True).logits[:, mask_idx, :]\n",
        "        probs = F.softmax(next_token_logits,dim=-1)\n",
        "        probability = probs[0,current_target]\n",
        "        current_context.append(current_target)\n",
        "        all_probabilities.append(probability.item())\n",
        "    all_probabilities = np.array(all_probabilities)\n",
        "    num_tokens = len(all_probabilities)\n",
        "    sum_surprisal = np.sum(-np.log2(all_probabilities))\n",
        "    sentence = tokenizer.decode(preceding_context[1:]+target_words)\n",
        "    full_sentence = tokenizer.decode(preceding_context[1:]+target_words+following_words)\n",
        "    target_string = tokenizer.decode(target_words)\n",
        "    with open(filename,\"a\") as f:\n",
        "        f.write(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\n\".format(\n",
        "            stimulus.replace(\"*\",\"\"),\n",
        "            sentence,\n",
        "            target_string,\n",
        "            sum_surprisal,\n",
        "            num_tokens\n",
        "        ))\n",
        "\n",
        "def process_stims_causal_mask(model,tokenizer,stimulus_file_list,metric_list,model_name_cleaned,output_directory,include_following_context):\n",
        "    for i in range(len(stimulus_file_list)):\n",
        "        stimuli_name = stimulus_file_list[i].split('/')[-1].split('.')[0]\n",
        "\n",
        "        if \"surprisal\" in metric_list:\n",
        "            filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".causal_mask.output\"\n",
        "            with open(filename,\"w\") as f:\n",
        "                f.write(\"FullSentence\\tSentence\\tTargetWords\\tSurprisal\\tNumTokens\\n\")\n",
        "\n",
        "        with open(stimulus_file_list[i],'r') as f:\n",
        "            stimulus_list = f.read().splitlines()\n",
        "        for j in range(len(stimulus_list)):\n",
        "            try:\n",
        "                stimulus = stimulus_list[j]\n",
        "                stimulus_spaces = stimulus.replace(\"*\", \"[!StimulusMarker!]\")\n",
        "                if (tokenizer.tokenize(\" a\")[0][0]==tokenizer.tokenize(\" b\")[0][0]) and (tokenizer.tokenize(\"a\")[0][0]!=tokenizer.tokenize(\"b\")[0][0]):\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\" [!StimulusMarker!]\", \"[!StimulusMarker!] \")\n",
        "                else:\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\"[!StimulusMarker!]\", \"[!StimulusMarker!] \")\n",
        "                    stimulus_spaces = stimulus_spaces.replace(\" [!StimulusMarker!]\", \"[!StimulusMarker!]\")\n",
        "                encoded_stimulus = tokenizer.encode(stimulus_spaces)[1:-1]\n",
        "\n",
        "                if (len(tokenizer.tokenize(\"a[!StimulusMarker!]\"))==2):\n",
        "                    dummy_var_idxs = np.where((np.array(encoded_stimulus)==tokenizer.encode(\"[!StimulusMarker!]\")[-2]) | (np.array(encoded_stimulus)==tokenizer.encode(\"a[!StimulusMarker!]\")[-2]))[0]\n",
        "                    preceding_context = encoded_stimulus[:dummy_var_idxs[0]]\n",
        "                    if (len(preceding_context)==0) or (not preceding_context[0]==tokenizer.bos_token_id):\n",
        "                        preceding_context = [tokenizer.bos_token_id] + preceding_context\n",
        "                    target_words = encoded_stimulus[dummy_var_idxs[0]+1:dummy_var_idxs[1]]\n",
        "                    following_words = encoded_stimulus[dummy_var_idxs[1]+1:]\n",
        "\n",
        "                    if \"surprisal\" in metric_list:\n",
        "                        get_surprisal_causal_mask(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,include_following_context,stimulus)\n",
        "            except:\n",
        "                print(\"Problem with stimulus on line {0}: {1}\\n\".format(str(j+1),stimulus_list[j]))\n",
        "\n",
        "def get_surprisal_causal_mask(model,tokenizer,preceding_context,following_words,target_words,stimuli_name,model_name_cleaned,output_directory,include_following_context,stimulus):\n",
        "    filename = output_directory + \"/\" + stimuli_name + \".\" + \"surprisal\" + \".\" + model_name_cleaned + \".causal_mask.output\"\n",
        "    current_context = copy.deepcopy(preceding_context)\n",
        "    all_probabilities = []\n",
        "    for i in range(len(target_words)):\n",
        "        current_target = target_words[i]\n",
        "        context_plus_mask = current_context + [tokenizer.mask_token_id]\n",
        "        if include_following_context==True:\n",
        "            context_plus_mask = context_plus_mask + following_words\n",
        "        model_input_list = context_plus_mask+[tokenizer.eos_token_id]\n",
        "        mask_idx = model_input_list.index(tokenizer.mask_token_id)\n",
        "        input = torch.LongTensor([model_input_list]).to(model.device)\n",
        "        with torch.no_grad():\n",
        "            next_token_logits = model(input, return_dict=True).logits[:, mask_idx, :]\n",
        "        probs = F.softmax(next_token_logits,dim=-1)\n",
        "        probability = probs[0,current_target]\n",
        "        current_context.append(current_target)\n",
        "        all_probabilities.append(probability.item())\n",
        "    all_probabilities = np.array(all_probabilities)\n",
        "    num_tokens = len(all_probabilities)\n",
        "    sum_surprisal = np.sum(-np.log2(all_probabilities))\n",
        "    sentence = tokenizer.decode(preceding_context[1:]+target_words)\n",
        "    full_sentence = tokenizer.decode(preceding_context[1:]+target_words+following_words)\n",
        "    target_string = tokenizer.decode(target_words)\n",
        "    with open(filename,\"a\") as f:\n",
        "        f.write(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\n\".format(\n",
        "            stimulus.replace(\"*\",\"\"),\n",
        "            sentence,\n",
        "            target_string,\n",
        "            sum_surprisal,\n",
        "            num_tokens\n",
        "        ))\n",
        "\n",
        "\n",
        "def main():\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    args = parse_args()\n",
        "    output_directory,primary_decoder,include_following_context,model_list,metric_list,stimulus_file_list,cpu = process_args(args)\n",
        "    create_and_run_models(model_list,stimulus_file_list,metric_list,primary_decoder,output_directory,include_following_context,cpu)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "b18a8d4ad67d477f861706eb10c5c6e5",
            "57964339f15d497499d98de589300427",
            "d0fac44e2f324e48bceb9d40cf2a5d3c",
            "25fde9721c7a4414aa61017eac03e817",
            "ebb7f2351d034ce5940096a877ccd059",
            "7b9e7d3ea9df4e1b95687940a3e76022",
            "44bee4f6e38f44eabcd89fb326f76348",
            "02055fd4c9404aba8a4ad063ef071245",
            "98a8a218d41c4d4998f4e0656956d59a",
            "2e04053aa4c1404db7e0f40a04b49fc5",
            "ee1b3a5b05ed4d739ce205ed599c3196",
            "16a0923fdfc14c2e8d41e8808bbfe393",
            "4e3fff7b3555462288c5ad4a89f81170",
            "4a7358c75d284b94b42b1da886aa1bba",
            "347a77047ba6457787696d7929254744",
            "51e22764e2744a1bb72e5a21504be7f5",
            "191562d7f7f240b4930d68a423081ba2",
            "d42d73def45645fe871e60913be98286",
            "61673cdf2b364666adddaec0a06f86ef",
            "2da524d068144a7b8f89fa5d47f40fed",
            "04742611830c47f49fc4ffe1909f75a5",
            "bd5dd151cf8240089c55bc3549d4a81e",
            "c24c8df340c64a6797c73c2d65b2316d",
            "1e3e25b13274488194fa41b72806e5f0",
            "ab246629e4e84c9195a08f28af06c6c8",
            "9e4de2ac2f884d55897bd3128d3128d6",
            "b5c582b1df8e4101a32f0a23be6cb92f",
            "72ed1e83f4d7482ba49191df9ddc55aa",
            "ffa84c19c5b442a8a24c27bc1aeed308",
            "48587f809e804064abe0e4293935a627",
            "bcf20adfaeb94fb387084f423aaf0fb6",
            "bbf2c71678e2430091ef260bd63ee1a5",
            "30a4cd7f36cb4bf0a0e2a0113253fc86",
            "67c4eab084f644ad9b553c34543d2d94",
            "2b3cd1301de74e13a82ed87338cb8cfc",
            "102edf0b4c554ad98108e1a812042c04",
            "d29db0d625ef48d0a896979789384759",
            "cb82bc3b977f431da72095521e427140",
            "b5cf1dbc08294eb9ae8690b24039e0c4",
            "ee0ba1585d574e92bf04a0b21ff43e24",
            "24a5942d7c1c49768a1b97e51bd2a536",
            "f08fc6b6e0a143f49e3d0e2efd675340",
            "2c062779fa434f3db3bc929288dc61a0",
            "556555f975e44d13974a3b83334d325e",
            "dfb7c75848d7484cad77d157d6bf67dc",
            "5d54ce618e50449185a98c5478d841b7",
            "c35c188cff534345b9b1360c6a55aaa4",
            "1fcd30b3e4e5463181bf9ae607fee3d6",
            "bec41b5e03844e6d9655407a26cf2070",
            "206cecacc480446a9c9b76039b817825",
            "b7279984c95c40cc9e58a247387cd6ad",
            "a5218404fe04443c9f2d36d86ff4f40a",
            "18ccbcd84d9741268c88688690c6ec94",
            "3a4b39ead96a46eea3e9ea428c317a90",
            "89c4f2e1085f4e008f7ee3bcd51624da",
            "0d70b64f136942859b0213312ada09e5",
            "b3b819d8fd284c398062505eb733f4bf",
            "fc2e502d24ee4197af338d09fa93b52c",
            "e18cab76591a466bab5f7166001c1eb9",
            "053e6a8a3d244640898e95cd92d5c20e",
            "30eb3d6a10024546bfd188625694b40a",
            "2e5bdf9341d24f1ea1cd334a1ab4423e",
            "34b7b2a6ec8441579acbc18dcefc7850",
            "36dd5faa1abd48249ffbb900aa41a1bf",
            "dd7f6a30f7814c688f4e74e002ac3bd3",
            "29cf035ddc1d40848c2975e33f89102f",
            "59522c73be824fb381422d51e9969517",
            "610a44aa952049e0b3df9d5c623a03f9",
            "1f4180b09d2f4760a8fa0e59846c6a34",
            "96e1a2e31b69451abbee48bb20df0064",
            "ddb96b6ea87b403e930f5cd6c3562201",
            "f697623267364d5f893b6cd59eb1fbd2",
            "f0ef719afcf842f48d2efa41ed904850",
            "923854fa798c4a7eb7ecd05e6c15d9c3",
            "213d2790225749eaa9037f7d238033d4",
            "6e6264e55a5a421096be5219d0104f60",
            "b43d981838e043e4887b7a814dad1afe"
          ]
        },
        "outputId": "ed023fb5-b150-4964-f54e-1aaad25b8e6f",
        "id": "hSONyfAPuWgr"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/236 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b18a8d4ad67d477f861706eb10c5c6e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "16a0923fdfc14c2e8d41e8808bbfe393"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c24c8df340c64a6797c73c2d65b2316d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67c4eab084f644ad9b553c34543d2d94"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dfb7c75848d7484cad77d157d6bf67dc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/739 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d70b64f136942859b0213312ada09e5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/7.18G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59522c73be824fb381422d51e9969517"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "English Version:\n",
        "text marking with **"
      ],
      "metadata": {
        "id": "3p0d6K9-TpXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def mark_and_split_sentences_in_paragraph(paragraph, output_filename=\"marked_sentences.txt\"):\n",
        "    \"\"\"Marks each word in each sentence of a paragraph with \"**\" and writes to a file.\n",
        "\n",
        "    Args:\n",
        "        paragraph: The input paragraph (string).\n",
        "        output_filename: The name of the output text file.\n",
        "    \"\"\"\n",
        "\n",
        "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s\\。\\；\\;', paragraph) # Robust sentence splitting\n",
        "    all_marked_sentences = []\n",
        "\n",
        "    for sentence in sentences:\n",
        "        words = re.findall(r'\\b\\w+\\b', sentence)\n",
        "        modified_sentences = []\n",
        "\n",
        "        for i in range(len(words)):\n",
        "            new_sentence = \"\"\n",
        "            word_index = 0\n",
        "            for word in re.split(r'\\b(\\w+)\\b', sentence):\n",
        "                if word.isalnum():\n",
        "                    if word_index == i:\n",
        "                        new_sentence += f\"*{word}*\"\n",
        "                    else:\n",
        "                        new_sentence += word\n",
        "                    word_index += 1\n",
        "                else:\n",
        "                    new_sentence += word\n",
        "            modified_sentences.append(new_sentence)\n",
        "\n",
        "        all_marked_sentences.extend(modified_sentences) # Add all variations of the current sentence\n",
        "\n",
        "    output_text = \"\\n\".join(all_marked_sentences)\n",
        "\n",
        "    try:\n",
        "        with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(output_text)\n",
        "        print(f\"Marked sentences written to {output_filename}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage:\n",
        "paragraph = \"\"\"大会主席先生，各位阁下，女士们、先生们，我们的世界正处于旋涡之中。我们正处在一个史诗般的变革时代，面临着我们从未见过的挑战，这些挑战需要全球性的解决方案。然而，地缘政治分歧不断加深。 地球持续升温。战争愈演愈烈，却不知如何收场。核姿态和新武器投下了阴影。我们正逐步走向难以想象的境地，一个有可能吞噬世界的火药桶。与此同时，2024年全球一半人会参加投票，而全人类都会受到影响。身临这一旋涡，面对在座诸位，我坚信两个最重要的事实。第一，当今世界的现状是不可持续的。我们不能再这样下去了。第二，我们面临的挑战是可以解决的。但这需要我们确保国际问题解决机制能够真正解决问题。未来峰会是第一步，但我们还有很长的路要走。要实现目标，必须正视造成不可持续性的三大因素。\n",
        "一个有罪不罚的世界--违法和侵权行为威胁着国际法和《联合国宪章》的根基；一个不平等的世界--不公正和不满情绪有可能削弱国家，甚至将其推向边缘；一个充满不确定性的世界—不加管理的全球风险以不可知的方式威胁着我们的未来。\"\"\"\n",
        "\n",
        "mark_and_split_sentences_in_paragraph(paragraph, \"test_output.txt\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HNEaYs4rTsvV",
        "outputId": "37a0225d-8cd4-482e-9513-bdfe2d5699ab"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Marked sentences written to test_output.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kp4JRezPh1nr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chinese Version of marking **"
      ],
      "metadata": {
        "id": "sS5bL2Hkh303"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import jieba\n",
        "import re\n",
        "\n",
        "\n",
        "def segment_and_mark_chinese_text(text, output_file):\n",
        "    \"\"\"\n",
        "    Segments Chinese text, marks each word with \"**\", and writes each marked word\n",
        "    on a new line with the original sentence surrounding it.  Takes text as input.\n",
        "\n",
        "    Args:\n",
        "        text: The Chinese text to process (string).\n",
        "        output_file: Path to the output file.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        with open(output_file, 'w', encoding='utf-8') as outfile:\n",
        "            # Split the input text into sentences or paragraphs based on common Chinese punctuation.\n",
        "            # You can customize this splitting if needed.\n",
        "           sentences = re.split(r\"[。？！；：.?!;]+\", text)\n",
        "           for sentence in sentences:\n",
        "                sentence = sentence.strip()  # Remove extra whitespace\n",
        "                if sentence:\n",
        "                    words = jieba.lcut(sentence)\n",
        "                    for word in words:\n",
        "                        marked_word = f\"*{word}*\"\n",
        "                        outfile.write(f\"{sentence.replace(word, marked_word)}\\n\")\n",
        "\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    chinese_text = \"\"\"\n",
        "    大会主席,诸位阁下,女士们先生们.我们的世界正处于旋风之中.我们现在处于巨大的变革的时代,面对的是前所未有的挑战,这些挑战要求有全球的解决方案.但是地缘政治的分歧不断加深.我们的星球不断升温.战争肆虐,没有人知道战争会如何终结.而核态势和新武器投下了黑暗的阴影.我们逐渐走向不可想象的结局，也就是会吞噬整个世界的火药桶与此同时,在2024年，全球一半的人类会进行大选,而大选的结果会影响所有的人.我今天站在这里，在这个旋风之中，相信有两个高于一切的真像.首先,我们世界的状态是不可持续的.我们不能够再一直这样下去.第二点,我们面对的挑战是可以解决的.这就要求我们要保证确保国际解决问题的机制能够实实在在地解决问题.未来峰会就是第一步,当然我们还有很长的路要走.而到达我们的终点,要求面对三个主要的，不可持续的驱动因素。首先有一个有罪不罚的世界，就是各种违法和侵权的行为威胁了国际法和《联合国宪章》的基石;还有一个不平等的世界--也就是不正义和布满威胁，伤害各国,会让他们陷入绝境。另外还有一个不确定的世界，也就是未经管理的全球威胁会威胁我们的未来，以不可想象的方式来威胁着我们的未来.\n",
        "    \"\"\"  # Paste your Chinese text here\n",
        "\n",
        "    output_filename = \"output.txt\"\n",
        "\n",
        "    segment_and_mark_chinese_text(chinese_text, output_filename)\n",
        "    print(f\"Segmentation and marking complete. Output written to '{output_filename}'\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1DmrfvYN_h7p",
        "outputId": "8ae6eea5-09f9-4bb4-f3a3-718af27da4a4"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 0.579 seconds.\n",
            "DEBUG:jieba:Loading model cost 0.579 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Segmentation and marking complete. Output written to 'output.txt'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA"
      ],
      "metadata": {
        "id": "dGGSt_Z0-QPN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prompt: allow me to elaborate. i have two sets of data. dataset 1 is on column A-D. column A is the group number, B is the data for the group called \"original\", C is the data for \"tsl\", and D is for the group \"int\". Similarly, the dataset 2 is on column F-I, with F being the group number, G the data for \"original\", H for \"tsl\", I for \"int\". What i want to do is conduct an ANOVA using python to compare B-C-D individually, and compare G-H-I individually."
      ],
      "metadata": {
        "id": "Hri-OhBP-a8I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
        "\n",
        "\n",
        "def perform_anova_and_posthoc(data, dependent_variable, group_variable):\n",
        "    \"\"\"Performs ANOVA and post-hoc test using scipy.\"\"\"\n",
        "    try:\n",
        "        # Perform ANOVA using scipy.stats.f_oneway\n",
        "        groups = data[group_variable].unique()\n",
        "        args = [data[data[group_variable] == g][dependent_variable] for g in groups]\n",
        "        fvalue, pvalue = stats.f_oneway(*args)\n",
        "\n",
        "        # Create ANOVA table (simplified)\n",
        "        anova_table = pd.DataFrame({\n",
        "            'Source': [group_variable, 'Residual'],\n",
        "            'F': [fvalue, np.nan],  # F-value for the group effect\n",
        "            'PR(>F)': [pvalue, np.nan]  # p-value for the group effect\n",
        "        }).set_index('Source')\n",
        "\n",
        "        group_means = data.groupby(group_variable)[dependent_variable].mean()\n",
        "\n",
        "        alpha = 0.05\n",
        "        if pvalue < alpha:  # Check p-value for significance\n",
        "            tukey = pairwise_tukeyhsd(data[dependent_variable], data[group_variable], alpha=alpha)\n",
        "            return anova_table, tukey, group_means\n",
        "        else:\n",
        "            return anova_table, None, group_means\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred: {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "\n",
        "# Load your Excel data (replace 'your_file.xlsx' with your file name)\n",
        "excel_file = pd.ExcelFile('/content/drive/MyDrive/PsychFormers/ANOVA/20250202ANOVA分析.xlsx')\n",
        "\n",
        "# Load Dataset 1\n",
        "df1 = excel_file.parse('Sheet1')  # Replace 'Sheet1' with your sheet name if needed\n",
        "df1 = df1.rename(columns={'A': 'Group', 'B': 'Original', 'C': 'TSL', 'D': 'INT'})  # Rename columns for clarity\n",
        "\n",
        "# Load Dataset 2\n",
        "df2 = excel_file.parse('Sheet1')  # Replace 'Sheet1' with your sheet name if needed\n",
        "df2 = df2.rename(columns={'F': 'Group', 'G': 'Original', 'H': 'TSL', 'I': 'INT'})  # Rename columns\n",
        "\n",
        "# Melt DataFrames to long format for ANOVA\n",
        "df1_long = pd.melt(df1, id_vars=['Group'], value_vars=['Original', 'TSL', 'INT'], var_name='Treatment', value_name='Value')\n",
        "df2_long = pd.melt(df2, id_vars=['Group'], value_vars=['Original', 'TSL', 'INT'], var_name='Treatment', value_name='Value')\n",
        "\n",
        "# Perform ANOVA and post-hoc tests for Dataset 1\n",
        "print(\"Dataset 1 Analysis:\")\n",
        "anova1, tukey1, means1 = perform_anova_and_posthoc(df1_long, 'Value', 'Treatment')\n",
        "if anova1 is not None:\n",
        "    print(\"ANOVA Table:\")\n",
        "    print(anova1)\n",
        "    print(\"\\nGroup Means:\")\n",
        "    print(means1)\n",
        "    if tukey1 is not None:\n",
        "        print(\"\\nTukey's HSD Post-Hoc Test:\")\n",
        "        print(tukey1)\n",
        "    else:\n",
        "        print(\"\\nANOVA was not significant, so Tukey's test was not performed.\")\n",
        "\n",
        "# Perform ANOVA and post-hoc tests for Dataset 2\n",
        "print(\"\\nDataset 2 Analysis:\")\n",
        "anova2, tukey2, means2 = perform_anova_and_posthoc(df2_long, 'Value', 'Treatment')\n",
        "if anova2 is not None:\n",
        "    print(\"ANOVA Table:\")\n",
        "    print(anova2)\n",
        "    print(\"\\nGroup Means:\")\n",
        "    print(means2)\n",
        "\n",
        "    if tukey2 is not None:\n",
        "        print(\"\\nTukey's HSD Post-Hoc Test:\")\n",
        "        print(tukey2)\n",
        "    else:\n",
        "        print(\"\\nANOVA was not significant, so Tukey's test was not performed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xicUvyCK-SD1",
        "outputId": "a054678e-c9f4-4b76-e6d5-6c9289ce4907"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset 1 Analysis:\n",
            "ANOVA Table:\n",
            "                  F   PR(>F)\n",
            "Source                      \n",
            "Treatment  1.105376  0.33846\n",
            "Residual        NaN      NaN\n",
            "\n",
            "Group Means:\n",
            "Treatment\n",
            "INT         101.589083\n",
            "Original     86.930012\n",
            "TSL          80.691654\n",
            "Name: Value, dtype: float64\n",
            "\n",
            "ANOVA was not significant, so Tukey's test was not performed.\n",
            "\n",
            "Dataset 2 Analysis:\n",
            "ANOVA Table:\n",
            "                  F   PR(>F)\n",
            "Source                      \n",
            "Treatment  1.105376  0.33846\n",
            "Residual        NaN      NaN\n",
            "\n",
            "Group Means:\n",
            "Treatment\n",
            "INT         101.589083\n",
            "Original     86.930012\n",
            "TSL          80.691654\n",
            "Name: Value, dtype: float64\n",
            "\n",
            "ANOVA was not significant, so Tukey's test was not performed.\n"
          ]
        }
      ]
    }
  ]
}